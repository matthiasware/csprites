{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e31046",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dca76b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from tqdm import tqdm\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1a1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2022374d",
   "metadata": {},
   "source": [
    "# Links\n",
    "- https://arxiv.org/pdf/1901.02739.pdf\n",
    "- https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Dirichlet?hl=de-deHarap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94397bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.2] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirdist = Dirichlet(torch.Tensor(alphas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b216bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "samples = dirdist.sample((n_samples, ))\n",
    "dir_plot3d(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2acc9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dirdist.log_prob(dirdist.sample((10, ))).mean())\n",
    "print(dirdist.log_prob(dirdist.sample((100, ))).mean())\n",
    "print(dirdist.log_prob(dirdist.sample((512, ))).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f049cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirdist_ske = Dirichlet(torch.Tensor([0.9, 0.05, 0.005]))\n",
    "dirdist_ide = Dirichlet(torch.Tensor([0.1, 0.1, 0.1]))\n",
    "dirdist_uni = Dirichlet(torch.Tensor([1, 1, 1]))\n",
    "dirdist_con = Dirichlet(torch.Tensor([10, 6, 7]))\n",
    "#\n",
    "dir_dists = [dirdist_ske, dirdist_ide, dirdist_uni, dirdist_con]\n",
    "dir_names = [\"skewed\", \"sparse\", \"uniform\", \"concentrated\"]\n",
    "n_samples = 1000\n",
    "dir_samples = [dist.sample((n_samples, )) for dist in dir_dists]\n",
    "#\n",
    "for x in dir_samples:\n",
    "    dir_plot3d((x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aeb7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "n_samples = 100\n",
    "for dist_1 in dir_dists:\n",
    "    dist_1_samples = dist_1.sample((n_samples, ))\n",
    "    dist_1_lls = []\n",
    "    for dist_2 in dir_dists:\n",
    "        dist_2_ll = dist_2.log_prob(dist_1_samples).mean()\n",
    "        dist_1_lls.append(dist_2_ll)\n",
    "    lls.append(dist_1_lls)\n",
    "#\n",
    "x = np.array(lls)\n",
    "plot_mat(x, dir_names, dir_names, title=\"log likelihoods dist(data)\", xlabel=\"Dist\", ylabel=\"Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d029d9b6",
   "metadata": {},
   "source": [
    "# 2D Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad968173",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirdist_ske = Dirichlet(torch.Tensor([0.99, 0.005]))\n",
    "dirdist_ide = Dirichlet(torch.Tensor([0.01, 0.01]))\n",
    "dirdist_uni = Dirichlet(torch.Tensor([1, 1]))\n",
    "dirdist_con = Dirichlet(torch.Tensor([10, 8,]))\n",
    "#\n",
    "dir_dists = [dirdist_ske, dirdist_ide, dirdist_uni, dirdist_con]\n",
    "dir_names = [\"skewed\", \"sparse\", \"uniform\", \"concentrated\"]\n",
    "n_samples = 100\n",
    "dir_samples = [dist.sample((n_samples, )) for dist in dir_dists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa94dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "for dist in dir_dists:\n",
    "    x = dist.sample((n_samples,))\n",
    "    dir_plot2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2ee68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lls = []\n",
    "n_samples = 1000\n",
    "for dist_1 in dir_dists:\n",
    "    dist_1_samples = dist_1.sample((n_samples, ))\n",
    "    dist_1_lls = []\n",
    "    for dist_2 in dir_dists:\n",
    "        dist_2_ll = dist_2.log_prob(dist_1_samples).sum()\n",
    "        dist_1_lls.append(dist_2_ll)\n",
    "    lls.append(dist_1_lls)\n",
    "#\n",
    "x = np.array(lls)\n",
    "plot_mat(x, dir_names, dir_names, title=\"log likelihoods dist(data)\", xlabel=\"Dist\", ylabel=\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d522db",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "for idx in range(len(dir_dists)):\n",
    "    dist = dir_dists[idx]\n",
    "    samples = dist.sample((n_samples, ))\n",
    "    mean = samples.mean(axis=0)\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim([0, 1])\n",
    "    plt.bar(range(len(mean)), mean)\n",
    "    plt.title(dir_names[idx])\n",
    "    plt.show()\n",
    "    print(samples.mean(axis=0), dist.mean)\n",
    "    print(samples.var(axis=0), dist.variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54aa5c",
   "metadata": {},
   "source": [
    "# BETA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b860f",
   "metadata": {},
   "source": [
    "- http://bariskurt.com/kullback-leibler-divergence-between-two-dirichlet-and-beta-distributions/\n",
    "- https://math.stackexchange.com/questions/257821/kullback-liebler-divergence\n",
    "- https://dibyaghosh.com/blog/probability/kldivergence.html\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1 = 2, 10\n",
    "a2, b2 = 10, 2\n",
    "a3, b3 = 0.4, 0.5\n",
    "n_samples = 100\n",
    "#\n",
    "\n",
    "x1 = np.random.beta(a1, b1, size=n_samples)\n",
    "x2 = np.random.beta(a2, b2, size=n_samples)\n",
    "x3 = np.random.beta(a3, b3, size=n_samples)\n",
    "#\n",
    "beta_plot1d(x1)\n",
    "beta_plot1d(x2)\n",
    "beta_plot1d(x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e46fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 0.4, 0.5\n",
    "n_samples = 100\n",
    "#\n",
    "x = np.random.beta(a, b, size=n_samples)\n",
    "beta_plot1d(x)\n",
    "beta_plot1d(1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a9c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = 2, 5\n",
    "n_samples = 100\n",
    "#\n",
    "x = np.random.beta(a, b, size=n_samples)\n",
    "beta_plot1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b1346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.beta(1/a, 1/b, size=n_samples)\n",
    "beta_plot1d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b589b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Beta\n",
    "\n",
    "def beta_params(X):\n",
    "    mu = X.mean()\n",
    "    var = X.var()\n",
    "    #\n",
    "    a = ((mu * (1 - mu)) / var - 1) * mu\n",
    "    b = ((mu * (1 - mu)) / var - 1) * (1 - mu)\n",
    "    return a, b\n",
    "\n",
    "def beta_params2(X):\n",
    "    mu = X.mean()\n",
    "    var = X.var()\n",
    "    #\n",
    "    a = ((1 - mu) / var - (1 / mu)) * mu**2\n",
    "    b = a * (1 / mu - 1)\n",
    "    return a, b\n",
    "\n",
    "def kl_beta_beta_pt(p, q):\n",
    "    sum_params_p = p.concentration1 + p.concentration0\n",
    "    sum_params_q = q.concentration1 + q.concentration0\n",
    "    t1 = q.concentration1.lgamma() + q.concentration0.lgamma() + (sum_params_p).lgamma()\n",
    "    t2 = p.concentration1.lgamma() + p.concentration0.lgamma() + (sum_params_q).lgamma()\n",
    "    t3 = (p.concentration1 - q.concentration1) * torch.digamma(p.concentration1)\n",
    "    t4 = (p.concentration0 - q.concentration0) * torch.digamma(p.concentration0)\n",
    "    t5 = (sum_params_q - sum_params_p) * torch.digamma(sum_params_p)\n",
    "    return t1 - t2 + t3 + t4 + t5\n",
    "\n",
    "def kl_beta_beta(ab_aprx, ab_true, forward=True):\n",
    "    \"\"\"\n",
    "    Calculates either:\n",
    "        Forward KL: D_kl(P||Q)\n",
    "        Reverse KL: D_kl(Q||P)\n",
    "    where:\n",
    "        P ... True distribution\n",
    "        Q ... Approximation\n",
    "    Forward:\n",
    "        - Mean seeking\n",
    "        - Where pdf(P) is high, pdf(Q) must be high\n",
    "    Reverse:\n",
    "        - Mode seeking\n",
    "        - where pdf(Q) is high, pdf(P) must be high\n",
    "    \"\"\"\n",
    "    if forward:\n",
    "        p_a, p_b = ab_aprx\n",
    "        q_a, q_b = ab_true\n",
    "    else:\n",
    "        p_a, p_b = ab_true\n",
    "        q_a, q_b = ab_aprx\n",
    "    #\n",
    "    sum_pab = p_a + p_b\n",
    "    sum_qab = q_a + q_b\n",
    "    #\n",
    "    t1 = q_b.lgamma() + q_a.lgamma() + (sum_pab).lgamma()\n",
    "    t2 = p_b.lgamma() + p_a.lgamma() + (sum_qab).lgamma()\n",
    "    t3 = (p_b - q_b) * torch.digamma(p_b)\n",
    "    t4 = (p_a - q_a) * torch.digamma(p_a)\n",
    "    t5 = (sum_qab - sum_pab) * torch.digamma(sum_pab)\n",
    "    return t1 - t2 + t3 + t4 + t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd24e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1 = torch.Tensor([8]), torch.Tensor([2])\n",
    "a2, b2 = 1/a1, 1/b1\n",
    "#\n",
    "d1 = Beta(a1, b1)\n",
    "d2 = Beta(a2, b2)\n",
    "#\n",
    "n_samples = 100\n",
    "x1 = d1.sample((n_samples, ))\n",
    "x2 = d2.sample((n_samples, ))\n",
    "#\n",
    "beta_plot1d(x1)\n",
    "beta_plot1d(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa1cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kl_beta_beta_pt(d2, d1))\n",
    "print(kl_beta_beta_pt(d1, d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5186b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kl_beta_beta(ab_aprx=(a2, b2), ab_true=(a1, b1), forward=True))\n",
    "print(kl_beta_beta(ab_aprx=(a2, b2), ab_true=(a1, b1), forward=False))\n",
    "#kl_beta_beta2((a1, b1), (a2, b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1864ef8",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8726f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_beta_pdf(dist, title=None):\n",
    "    xx = torch.linspace(0, 1,200)[1:-1]\n",
    "    plt.plot(xx, torch.exp(dist.log_prob(xx)))\n",
    "    a, b = float(dist.concentration0), float(dist.concentration1)\n",
    "    if title is not None:\n",
    "        plt.title(\"{} \\n a={:.3f}, beta={:.3f}\".format(\n",
    "            title, a, b))\n",
    "    else:\n",
    "        plt.title(\"a={:.3f}, beta={:.3f}\".format(a, b))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf9fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "#\n",
    "a_true, b_true = 0.2, 0.5\n",
    "d_true = Beta(a_true, b_true)\n",
    "#\n",
    "d_aprx = Beta(1/b_true, 1/a_true)\n",
    "x_aprx = d_aprx.sample((n_samples,))\n",
    "#\n",
    "a_aprx, b_aprx = beta_params(x_aprx)\n",
    "a_aprx, b_aprx = 1/b_aprx, 1/a_aprx\n",
    "#\n",
    "print(\"P = Beta({:.3f},{:.3f})\".format(a_true, b_true))\n",
    "print(\"Q = Beta({:.3f},{:.3f})\".format(a_aprx, b_aprx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6c5d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_beta_pdf(d_true, title=\"True\")\n",
    "plot_beta_pdf(d_aprx, title=\"Approx\")\n",
    "plot_beta_pdf(d_aprx, title=\"Estimated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ab6580",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, b1 = torch.Tensor([0.2]), torch.Tensor([0.8])\n",
    "#a2, b2 = 1/a1, 1/b1\n",
    "a3, b3 = 1/b1, 1/a1\n",
    "\n",
    "d1 = Beta(a1, b1)\n",
    "#d2 = Beta(a2, b2)\n",
    "d3 = Beta(a3, b3)\n",
    "#\n",
    "plot_beta_pdf(d1)\n",
    "#plot_beta_pdf(d2, title=\"GW\")\n",
    "plot_beta_pdf(d3, title=\"GW\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0443a3",
   "metadata": {},
   "source": [
    "## Feature Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90676d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_log_prob(x, alphas):\n",
    "    #x = torch.stack([x, 1-x], dim=1)\n",
    "    ll_unomalized = (torch.log(x) * (alphas - 1.0)).sum(-1)\n",
    "    ll_normalizer = torch.lgamma(alphas.sum(-1)) - torch.lgamma(alphas).sum(-1)\n",
    "    return ll_unomalized + ll_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "alpha_factor = 10\n",
    "\n",
    "alphas = torch.Tensor([alpha, alpha * alpha_factor])\n",
    "n_samples = 500\n",
    "dist = Dirichlet(alphas)\n",
    "x = dist.sample((n_samples, ))\n",
    "dir_plot2d(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d584ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x\n",
    "x2 = torch.stack([x[:,0], 1-x[:,0]], dim=1)\n",
    "x3 = torch.stack([1 - x[:,1], x[:,1]], dim=1)\n",
    "#\n",
    "#print(x1.sum(axis=1))\n",
    "#print(x2.sum(axis=1))\n",
    "#print(x3.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist.log_prob(x1).sum())\n",
    "print(dir_log_prob(x1, alphas).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a86abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist.log_prob(x2).sum())\n",
    "print(dir_log_prob(x2, alphas).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995890c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist.log_prob(x3).sum())\n",
    "print(dir_log_prob(x3, alphas).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8290a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand((n_samples,))\n",
    "x1 = torch.stack([x, 1-x], dim=1)\n",
    "x2 = torch.stack([1 - x, x], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc9706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dist.log_prob(x1).sum())\n",
    "print(dist.log_prob(x2).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079131b1",
   "metadata": {},
   "source": [
    "# Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dgamma = torch.distributions.Gamma(alphas[0], alphas[1])\n",
    "x = dgamma.sample((n_samples, ))\n",
    "dir_plot2d(torch.stack([x, 1-x], dim=1))\n",
    "dir_plot2d(torch.stack([1 - x, x], dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff34c68",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc8951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#\n",
    "from tqdm import tqdm\n",
    "from torch.distributions.dirichlet import Dirichlet\n",
    "import math\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d4ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(x, rate=0.05):\n",
    "    n, d = x.shape\n",
    "    #\n",
    "    x_aug = x.clone()\n",
    "    #\n",
    "    for d_idx in range(d - 1):\n",
    "        eps = (torch.rand((n,))  * 2 - 1) * rate\n",
    "        x_aug[:, d_idx] = torch.clamp(x_aug[:, d_idx] + eps, min=0, max=1)\n",
    "    diff = 1 - x_aug[:, :-1].sum(axis=1) - x_aug[:, -1]\n",
    "    x_aug[:, -1] += diff\n",
    "    return x_aug\n",
    "\n",
    "def calc_lambda(d):\n",
    "    return 1 / ((d - 1) * 0.0244)\n",
    "\n",
    "def off_diagonal(x):\n",
    "    # return a flattened view of the off-diagonal elements of a square matrix\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, d_in, d_out,\n",
    "                 d_hid, n_hid,\n",
    "                 d_proj, n_proj,\n",
    "                 alphas,\n",
    "                 w_ll,\n",
    "                 w_var,\n",
    "                 lambd=None):\n",
    "        super().__init__()\n",
    "        self.w_var = w_var\n",
    "        assert n_hid >= 0\n",
    "        dims = [d_in] + [d_hid] * n_hid\n",
    "        self.dims = dims\n",
    "        self.alphas = alphas\n",
    "        self.dist = Dirichlet(alphas)\n",
    "        self.w_ll = w_ll\n",
    "        layers = []\n",
    "        for idx in range(len(dims) - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(dims[idx], dims[idx + 1]),\n",
    "                nn.BatchNorm1d(dims[idx + 1]),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ])\n",
    "        layers.extend([\n",
    "            nn.Linear(dims[-1], d_out),\n",
    "            #nn.BatchNorm1d(d_out),\n",
    "            nn.Softmax(dim=1)\n",
    "        ])\n",
    "        self.ff = nn.Sequential(*layers)\n",
    "        self.bn = nn.BatchNorm1d(d_proj, affine=False)\n",
    "        if lambd is None:\n",
    "            self.lambd = calc_lambda(d_out)\n",
    "        else:\n",
    "            self.lambd = lambd\n",
    "        \n",
    "        if n_proj > 0:\n",
    "            proj_dims = [d_out] + [d_proj] * n_proj\n",
    "            layers = []\n",
    "            for i in range(len(proj_dims) - 2):\n",
    "                layers.append(nn.Linear(proj_dims[i], proj_dims[i + 1], bias=False))\n",
    "                layers.append(nn.BatchNorm1d(proj_dims[i + 1]))\n",
    "                layers.append(nn.ReLU(inplace=True))\n",
    "            layers.append(nn.Linear(proj_dims[-2], proj_dims[-1], bias=False))\n",
    "            self.projector = nn.Sequential(*layers)\n",
    "        else:\n",
    "            self.projector =nn.Identity()\n",
    "            self.bn = nn.BatchNorm1d(d_out, affine=False)\n",
    "        \n",
    "    def representation(self, x):\n",
    "        return self.ff(x)\n",
    "\n",
    "    def forward(self, z1, z2):\n",
    "        z1 = self.ff(z1)\n",
    "        z2 = self.ff(z2)\n",
    "        #\n",
    "        ll = - 1 * self.dist.log_prob(torch.cat([z1, z2], axis=0)).sum()\n",
    "        #\n",
    "        l_var = torch.nn.functional.mse_loss(torch.cat([z1, z2], axis=0).var(axis=0), z_dist.variance)\n",
    "        l_mean = torch.nn.functional.mse_loss(torch.cat([z1, z2], axis=0).mean(axis=0), z_dist.mean)\n",
    "        l_mom = self.w_var * (l_mean + l_var)\n",
    "        #\n",
    "        z1 = self.projector(z1)\n",
    "        z2 = self.projector(z2)\n",
    "        #\n",
    "        c = self.bn(z1).T @ self.bn(z2)\n",
    "        c.div_(z1.shape[0])\n",
    "        #\n",
    "        on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()    break\n",
    "        off_diag = off_diagonal(c).pow_(2).sum()\n",
    "        barlow_loss =  on_diag + self.lambd * off_diag\n",
    "        #\n",
    "        loss = barlow_loss + ll * self.w_ll + self.w_var * l_var\n",
    "        return loss, barlow_loss, ll, l_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dad2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = 3\n",
    "d_out = 3\n",
    "d_hid = 32\n",
    "n_hid = 3\n",
    "d_proj = 3 * d_out\n",
    "n_proj = 3\n",
    "#\n",
    "w_ll = 0.01\n",
    "lambd = 100\n",
    "aw1 = 0.02\n",
    "aw2 = 0.02\n",
    "w_var = 5000\n",
    "#\n",
    "alphas_z = torch.rand(d_in) * 0.1\n",
    "alphas_x = torch.Tensor([8, 2, .1])\n",
    "alphas_z = torch.Tensor([0.01, 0.9, 0.9])\n",
    "#\n",
    "x_dist = Dirichlet(alphas_x)\n",
    "z_dist = Dirichlet(alphas_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae8c695",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_dist.sample((10,))\n",
    "#\n",
    "x1 = augment(x, aw1)\n",
    "x2 = augment(x, aw2)\n",
    "#\n",
    "dir_plot(x1)\n",
    "dir_plot(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0490a9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if d_in == 3:\n",
    "    n_samples = 1000\n",
    "    for dist in [x_dist, z_dist]:\n",
    "        dir_plot(dist.sample((n_samples,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(\n",
    "    d_in = d_in,\n",
    "    d_out = d_out,\n",
    "    d_hid = d_hid,\n",
    "    n_hid = n_hid,\n",
    "    d_proj = d_proj,\n",
    "    n_proj = n_proj,\n",
    "    alphas = alphas_z,\n",
    "    w_ll = w_ll,\n",
    "    w_var = w_var,\n",
    "    lambd=lambd\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d10620",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = x_dist.sample((batch_size, ))\n",
    "with torch.no_grad():\n",
    "        z = model.representation(x)\n",
    "z_real = z_dist.sample((batch_size, ))\n",
    "dir_plot(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734c536",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "#\n",
    "n_epochs = 10\n",
    "n_steps = 1000\n",
    "batch_size = 1024\n",
    "#\n",
    "for epoch_idx in range(n_epochs):\n",
    "    desc = \"Epoch [{:3}/{:3}] {}:\".format(epoch_idx, n_epochs, 'train')\n",
    "    pbar = tqdm(range(n_steps), bar_format= desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    epoch_loss = 0.\n",
    "    epoch_loss_bt = 0.\n",
    "    epoch_loss_ll = 0.\n",
    "    epoch_loss_var = 0.\n",
    "    epoch_step = 0\n",
    "    for step_idx in pbar:\n",
    "        model.train()\n",
    "        x = x_dist.sample((batch_size, ))\n",
    "        #\n",
    "        x1 = augment(x, aw1)\n",
    "        x2 = augment(x, aw2)\n",
    "        #\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        loss, barlow_loss, ll_loss, l_var = model(x1, x2)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #\n",
    "        epoch_step += 1\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_loss_bt += barlow_loss.item()\n",
    "        epoch_loss_ll += ll_loss.item()\n",
    "        epoch_loss_var += l_var.item()\n",
    "        #\n",
    "        pbar.set_postfix({'loss': loss.item(),\n",
    "                          'barlow': barlow_loss.item(),\n",
    "                          'll': ll_loss.item(),\n",
    "                          'lvar': l_var.item()\n",
    "                         })\n",
    "        \n",
    "    \n",
    "    if epoch_idx % 1 == 0:\n",
    "        print(\"   Loss: {:.2f} BL: {:.2f} LL: {:.2f} VL: {:.2f}\".format(\n",
    "            epoch_loss / epoch_step,\n",
    "            epoch_loss_bt / epoch_step,\n",
    "            epoch_loss_ll / epoch_step,\n",
    "            epoch_loss_var / epoch_step\n",
    "        ))\n",
    "        if d_out == 3:\n",
    "            model.eval()\n",
    "            x = x_dist.sample((batch_size, ))\n",
    "            with torch.no_grad():\n",
    "                z = model.representation(x)\n",
    "            z_real = z_dist.sample((batch_size, ))\n",
    "            #dir_plot(x)\n",
    "            dir_plot(z)\n",
    "            #dir_plot(z_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73d297d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.nn.functional.mse_loss(x.mean(axis=0),z_dist.mean))\n",
    "print(torch.nn.functional.mse_loss(x.var(axis=0), z_dist.variance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b01ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.var(axis=0), z_dist.variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dist.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a789a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c9e042",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "model.eval()\n",
    "x = x_dist.sample((n_samples, ))\n",
    "with torch.no_grad():\n",
    "    z_pred = model.representation(x)\n",
    "z_real = z_dist.sample((n_samples,))\n",
    "#\n",
    "dir_plot(x)\n",
    "dir_plot(z_pred)\n",
    "dir_plot(z_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20787f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_x = z_dist.log_prob(x).sum()\n",
    "ll_z_pred = z_dist.log_prob(z_pred).sum()\n",
    "ll_z_real = z_dist.log_prob(z_real).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ll_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2283c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ll_z_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f5a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ll_z_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b3ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
