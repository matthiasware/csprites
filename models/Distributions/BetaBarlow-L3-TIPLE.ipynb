{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cc1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf4e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TORCH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet18\n",
    "\n",
    "# MISC\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dotted_dict import DottedDict\n",
    "import pickle\n",
    "\n",
    "from BTwins.utils import calc_lambda\n",
    "from BTwins.barlow import *\n",
    "from BTwins.transform_utils import *\n",
    "from Beta.models import *\n",
    "from csprites.datasets import ClassificationDataset\n",
    "import utils\n",
    "from backbone import get_backbone\n",
    "from optimizer import get_optimizer\n",
    "from functions import *\n",
    "from plot_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eddd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # CUDA SETTINGS\n",
    "    'device': 'cuda',\n",
    "    'cuda_visible_devices': '1',\n",
    "    \n",
    "    # DATA\n",
    "    #'p_data': \"/mnt/data/csprites/single_csprites_64x64_n7_c8_a8_p12_s1_bg_1_constant_color_64512\",\n",
    "    #'p_data': \"/mnt/data/csprites/single_csprites_64x64_n7_c8_a16_p4_s3_bg_inf_random_function_43008\",\n",
    "    'p_data': '/mnt/data/csprites/single_csprites_64x64_n7_c32_a16_p38_s1_bg_1_constant_color_70000',\n",
    "    'target_variable': 'shape',\n",
    "    \n",
    "    # TRAIN\n",
    "    'batch_size': 512,\n",
    "    'num_workers': 24,\n",
    "    'num_epochs': 20,\n",
    "    'freqs': {\n",
    "        'ckpt': 100,             # epochs\n",
    "        'linprob': 5,            # epochs\n",
    "        'plot_features': np.inf,     # epochs\n",
    "        'plot_classes': np.inf,  # epochs\n",
    "    },\n",
    "    'num_vis': 64,\n",
    "    \n",
    "    # backbone\n",
    "    'backbone': \"FCN8i223o32\",\n",
    "    'backbone_args': {\n",
    "        'ch_last': 32,\n",
    "        'dim_in': 3,\n",
    "    },\n",
    "    # projectors\n",
    "    'beta_projector': [64,64],\n",
    "    'barlow_projector': [],\n",
    "    'optimizer': 'adam',\n",
    "    'optimizer_args': {\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 1e-6\n",
    "    },\n",
    "    # LOSS\n",
    "    'r_stl': 0.35,\n",
    "    'r_geo': 0.35,\n",
    "    'w_beta': 1,\n",
    "    'w_barlow': 1,\n",
    "    'a_true': 0.1,\n",
    "    'b_true': 0.9,\n",
    "    'w_off': None, # SET ADAPTIVE\n",
    "    'w_on': 10,\n",
    "    \n",
    "    # PATH STUFF\n",
    "    'p_ckpts': \"ckpts\",\n",
    "    'p_model': \"model_{}.ckpt\",\n",
    "    'p_stats': \"stats.pkl\",\n",
    "    'p_config': 'config.pkl',\n",
    "    'p_R_train': 'R_train.npy',\n",
    "    'p_R_valid': 'R_valid.npy',\n",
    "    'p_Y_valid': 'Y_valid.npy',\n",
    "    'p_Y_train': 'Y_train.npy',\n",
    "    'p_R_train_bb': 'R_train_bb.npy',\n",
    "    'p_R_valid_bb': 'R_valid_bb.npy',\n",
    "    'p_Y_valid_bb': 'Y_valid_bb.npy',\n",
    "    'p_Y_train_bb': 'Y_train_bb.npy',\n",
    "}\n",
    "\n",
    "p_base = Path(\"/mnt/experiments/csprites\") / Path(config[\"p_data\"]).name / \"tmp\"\n",
    "\n",
    "# PATHS\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#2\n",
    "config[\"p_experiment\"] = str(p_base / \"Beta_[{}_d]_target_[{}]_{}\".format(\n",
    "    config[\"backbone\"],\n",
    "    config[\"backbone_args\"][\"ch_last\"],\n",
    "    config[\"target_variable\"],\n",
    "    st))\n",
    "config = DottedDict(config)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb92ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH SETTINGS\n",
    "torch.backends.cudnn.benchmark = True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.cuda_visible_devices\n",
    "device = torch.device(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229eb267",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a915f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ds_config = Path(config.p_data) / \"config.pkl\"\n",
    "\n",
    "with open(p_ds_config, \"rb\") as file:\n",
    "    ds_config = pickle.load(file)\n",
    "\n",
    "target_variable = config.target_variable\n",
    "target_idx = [idx for idx, target in enumerate(ds_config[\"classes\"]) if target == target_variable][0]\n",
    "n_classes = ds_config[\"n_classes\"][target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b2836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_transform = utils.normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"])\n",
    "inverse_norm_transform = utils.inverse_normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"]\n",
    ")\n",
    "target_transform = lambda x: x[target_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea58faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSpritesTripleTransform(torch.nn.Module):\n",
    "    def __init__(self, init_transform, geo_transform, stl_transform, fin_transform):\n",
    "        super().__init__()\n",
    "        self.init_transform = init_transform\n",
    "        self.stl_transform = stl_transform\n",
    "        self.geo_transform = geo_transform\n",
    "        self.fin_transform = fin_transform\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.init_transform(x)\n",
    "        #\n",
    "        x_geo = self.stl_transform(x)\n",
    "        x_stl = self.geo_transform(x)\n",
    "        #\n",
    "        if self.fin_transform is not None:\n",
    "            x = self.fin_transform(x)\n",
    "            x_stl = self.fin_transform(x_stl)\n",
    "            x_geo = self.fin_transform(x_geo)\n",
    "        return x, x_stl, x_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84c7d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_transform = utils.normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"])\n",
    "inverse_norm_transform = utils.inverse_normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"]\n",
    ")\n",
    "target_transform = lambda x: x[target_idx]\n",
    "#\n",
    "init_transform = lambda x: x\n",
    "stl_transform = transforms.Compose([\n",
    "                transforms.RandomApply(\n",
    "                    [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                            saturation=0.2, hue=0.1)],\n",
    "                    p=0.8\n",
    "                ),\n",
    "                transforms.RandomGrayscale(p=0.2),\n",
    "                GaussianBlur(p=0.5),\n",
    "                Solarization(p=0.2)\n",
    "])\n",
    "\n",
    "geo_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(ds_config[\"img_size\"],\n",
    "                                 scale=(0.4, 1.0),\n",
    "                                 ratio=(1, 1),\n",
    "                                 interpolation=Image.BICUBIC),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "fin_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                norm_transform\n",
    "            ])\n",
    "\n",
    "train_transform = CSpritesTripleTransform(\n",
    "    init_transform = init_transform,\n",
    "    stl_transform=stl_transform,\n",
    "    geo_transform=geo_transform,\n",
    "    fin_transform=fin_transform\n",
    ")\n",
    "\n",
    "transform_linprob = transforms.Compose([\n",
    "                transforms.Resize(ds_config[\"img_size\"]),\n",
    "                transforms.ToTensor(),\n",
    "                norm_transform\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e7c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "ds_train = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform,\n",
    "    split=\"train\"\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=False,\n",
    "    drop_last=True\n",
    ")\n",
    "# LINPROB\n",
    "ds_linprob_train = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=target_transform,\n",
    "    split=\"train\"\n",
    ")\n",
    "dl_linprob_train = DataLoader(\n",
    "    ds_linprob_train,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = config.num_workers,\n",
    "    pin_memory=False\n",
    ")\n",
    "ds_linprob_valid = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=target_transform,\n",
    "    split=\"valid\"\n",
    ")\n",
    "dl_linprob_valid = DataLoader(\n",
    "    ds_linprob_valid,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = config.num_workers,\n",
    "    pin_memory=False\n",
    ")\n",
    "print(len(dl_train))\n",
    "print(len(dl_linprob_train))\n",
    "print(len(dl_linprob_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db94a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL with all Features\n",
    "ds_eval_train = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=None,\n",
    "    split=\"train\"\n",
    ")\n",
    "dl_eval_train = DataLoader(\n",
    "    ds_eval_train,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = config.num_workers,\n",
    "    pin_memory=False\n",
    ")\n",
    "ds_eval_valid = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=None,\n",
    "    split=\"valid\"\n",
    ")\n",
    "dl_eval_valid = DataLoader(\n",
    "    ds_eval_valid,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = config.num_workers,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030493c8",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd31af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2e766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_train\n",
    "(x_ori, x_stl, x_geo),_ = next(iter(dl_train))\n",
    "#\n",
    "x_ori = inverse_norm_transform(x_ori[:n_vis])\n",
    "x_stl = inverse_norm_transform(x_stl[:n_vis])\n",
    "x_geo = inverse_norm_transform(x_geo[:n_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe8c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(x_geo, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "grid_img = torchvision.utils.make_grid(x_ori, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "#\n",
    "grid_img = torchvision.utils.make_grid(x_stl, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1d223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_linprob_train\n",
    "x,y = next(iter(dl_linprob_train))\n",
    "x = x[:n_vis]\n",
    "y = y[:n_vis]\n",
    "#\n",
    "x = inverse_norm_transform(x)\n",
    "#\n",
    "grid_img = torchvision.utils.make_grid(x, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "#\n",
    "y = [ds_config[\"class_maps\"][\"shape\"][idx.item()] for idx in y]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce02efb",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13869648",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BetaBarlowTwins(nn.Module):\n",
    "    def __init__(self, backbone, beta_projector, barlow_projector, dim_stl, dim_geo, dim_cnt):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.beta_projector = beta_projector\n",
    "        self.barlow_projector = barlow_projector\n",
    "        self.dim_stl = dim_stl\n",
    "        self.dim_geo = dim_geo\n",
    "        self.dim_cnt = dim_cnt\n",
    "\n",
    "        self.bn_stl = nn.BatchNorm1d(self.dim_stl, affine=False)\n",
    "        self.bn_geo = nn.BatchNorm1d(self.dim_geo, affine=False)\n",
    "        self.bn_cnt = nn.BatchNorm1d(self.dim_cnt, affine=False)\n",
    "\n",
    "    def backbone_proj(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def beta_proj(self, x):\n",
    "        return self.beta_projector(self.backbone(x))\n",
    "\n",
    "    def barlow_proj(self, x):\n",
    "        return self.barlow_projector(self.beta_proj(x))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.beta_proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0750ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone\n",
    "backbone = get_backbone(config.backbone, **config.backbone_args)\n",
    "\n",
    "# beta projector\n",
    "beta_projector = get_projector(planes_in=backbone.dim_out, sizes=config.beta_projector, activation_last=\"Sigmoid\")\n",
    "\n",
    "# barlow projector\n",
    "barlow_projector = get_projector(planes_in=beta_projector.dim_out, sizes=config.barlow_projector)\n",
    "\n",
    "# stl vs geo\n",
    "dim_stl = int(config.r_stl * barlow_projector.dim_out)\n",
    "dim_geo = int(config.r_geo * barlow_projector.dim_out)\n",
    "dim_cnt = barlow_projector.dim_out - dim_stl - dim_geo\n",
    "#\n",
    "if config[\"w_off\"] is None:\n",
    "    config[\"w_off\"] = calc_lambda(dim_stl)\n",
    "#\n",
    "\n",
    "model = BetaBarlowTwins(backbone, beta_projector, barlow_projector, dim_stl, dim_geo, dim_cnt)\n",
    "print(\"#params\", utils.count_parameters(model))\n",
    "#\n",
    "if torch.cuda.device_count() > 1 and device != \"cpu\":\n",
    "    print(\"Using {} gpus!\".format(torch.cuda.device_count()))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.backbone = model.module.backbone\n",
    "elif device != \"cpu\":\n",
    "    print(\"Using 1 GPU!\")\n",
    "else:\n",
    "    print(\"Using CPU!\")\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e51fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(config.optimizer, model.parameters(), config.optimizer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7c2f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'train': {\n",
    "        'loss': [],\n",
    "        'loss_beta': [],\n",
    "        'loss_barlow': [],\n",
    "        'loss_on': [],\n",
    "        'loss_off': [],\n",
    "        'a_min': [],\n",
    "        'a_mean': [],\n",
    "        'a_max': [],\n",
    "        'b_min': [],\n",
    "        'b_mean': [],\n",
    "        'b_max': [],\n",
    "        'epoch': [],\n",
    "    },\n",
    "    'linprob': {\n",
    "        'linacc': [],\n",
    "        'knnacc': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "}\n",
    "stats = DottedDict(stats)\n",
    "#\n",
    "p_experiment = Path(config.p_experiment)\n",
    "p_experiment.mkdir(exist_ok=True, parents=True)\n",
    "p_ckpts = p_experiment / config.p_ckpts\n",
    "p_ckpts.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.p_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27a25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cc_loss(z1, z2):\n",
    "    c = z1.T @ z2\n",
    "    c.div_(z1.shape[0])\n",
    "        \n",
    "    on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
    "    off_diag = off_diagonal(c).pow_(2).sum()\n",
    "    return on_diag, off_diag\n",
    "\n",
    "def cc_zero_loss(z1, z2):\n",
    "    c = z1.T @ z2\n",
    "    c.div_(z1.shape[0])\n",
    "    #\n",
    "    return c.pow_(2).sum()\n",
    "\n",
    "def feature_split(z, d_stl, d_cnt, d_geo):\n",
    "    z_stl = z[:, :d_stl]\n",
    "    z_cnt = z[:, d_stl: d_cnt + d_geo]\n",
    "    z_geo = z[:, d_cnt + d_geo:]\n",
    "    return z_stl, z_cnt, z_geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3c04ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand((10, 64))\n",
    "z_stl, z_cnt, z_geo = feature_split(z, dim_stl, dim_cnt, dim_geo)\n",
    "print(z_stl.shape)\n",
    "print(z_cnt.shape)\n",
    "print(z_geo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199ed2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_true, b_true = torch.Tensor([config.a_true, config.b_true])\n",
    "dist_true = Beta(a_true, b_true)\n",
    "plot_beta_pdf(dist_true, \"True\")\n",
    "#\n",
    "global_step = 0\n",
    "for epoch_idx in range(1, config.num_epochs + 1, 1):\n",
    "    ################\n",
    "    # TRAIN\n",
    "    ################\n",
    "    model.train()\n",
    "    \n",
    "    # STATS\n",
    "    epoch_step = 0\n",
    "    epoch_loss = 0\n",
    "    epoch_loss_beta = 0\n",
    "    epoch_loss_barlow = 0\n",
    "    epoch_loss_on = 0\n",
    "    epoch_loss_off = 0\n",
    "    epoch_a_min = 0\n",
    "    epoch_a_mean = 0\n",
    "    epoch_a_max = 0\n",
    "    epoch_b_min = 0\n",
    "    epoch_b_mean = 0\n",
    "    epoch_b_max = 0\n",
    "    #\n",
    "    desc = \"[{:3}/{:3}]\".format(epoch_idx, config.num_epochs)\n",
    "    pbar = tqdm(dl_train, bar_format= desc + '{bar:10}{n_fmt}/{total_fmt}{postfix}')\n",
    "    #\n",
    "    for (x_ori, x_stl, x_geo), _ in pbar:\n",
    "        x_ori = x_ori.to(device)\n",
    "        x_stl = x_stl.to(device)\n",
    "        x_geo = x_geo.to(device)\n",
    "\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        \n",
    "        ######################\n",
    "        # BETA LOSS\n",
    "        ######################\n",
    "\n",
    "        z_ori = model.beta_proj(x_ori)\n",
    "        z_stl = model.beta_proj(x_stl)\n",
    "        z_geo = model.beta_proj(x_geo)\n",
    "\n",
    "        if config.w_beta == 0:\n",
    "            with torch.no_grad():\n",
    "                a_z, b_z = beta_params(torch.cat([z_ori, z_stl, z_geo], axis=0))\n",
    "                loss_beta = kl_beta_beta((a_z,b_z),(a_true,b_true),forward=True).sum()\n",
    "        else:\n",
    "            a_z, b_z = beta_params(torch.cat([z_ori, z_stl, z_geo], axis=0))\n",
    "            loss_beta = kl_beta_beta((a_z,b_z),(a_true,b_true),forward=True).sum()\n",
    "        \n",
    "        ######################\n",
    "        # BARLOW  LOSS\n",
    "        ######################\n",
    "        \n",
    "        z_ori = model.barlow_projector(z_ori)\n",
    "        z_stl = model.barlow_projector(z_stl)\n",
    "        z_geo = model.barlow_projector(z_geo)\n",
    "        \n",
    "        z_ori_stl, z_ori_cnt, z_ori_geo = feature_split(z_ori, dim_stl, dim_cnt, dim_geo)\n",
    "        z_stl_stl, z_stl_cnt, z_stl_geo = feature_split(z_stl, dim_stl, dim_cnt, dim_geo)\n",
    "        z_geo_stl, z_geo_cnt, z_geo_geo = feature_split(z_geo, dim_stl, dim_cnt, dim_geo)\n",
    "        \n",
    "        # --------\n",
    "        # Normalize\n",
    "        # --------\n",
    "        z_ori_stl = model.bn_stl(z_ori_stl)\n",
    "        z_stl_stl = model.bn_stl(z_stl_stl)\n",
    "        z_geo_stl = model.bn_stl(z_geo_stl)\n",
    "        #\n",
    "        z_ori_cnt = model.bn_cnt(z_ori_cnt)\n",
    "        z_stl_cnt = model.bn_cnt(z_stl_cnt)\n",
    "        z_geo_cnt = model.bn_cnt(z_geo_cnt)\n",
    "        #\n",
    "        z_ori_geo = model.bn_geo(z_ori_geo)\n",
    "        z_stl_geo = model.bn_geo(z_stl_geo)\n",
    "        z_geo_geo = model.bn_geo(z_geo_geo)\n",
    "        #\n",
    "        \n",
    "        # this kind of works\n",
    "        on_diag_stl, off_diag_stl = cc_loss(z_ori_stl, z_stl_stl)\n",
    "        on_diag_geo, off_diag_geo = cc_loss(z_ori_geo, z_geo_geo)\n",
    "        on_diag_cnt, off_diag_cnt = cc_loss(z_stl_cnt, z_geo_cnt)\n",
    "        #\n",
    "        on_diag = on_diag_stl + on_diag_geo + on_diag_cnt\n",
    "        off_diag = off_diag_stl + off_diag_geo + off_diag_cnt\n",
    "        #\n",
    "        \n",
    "        #on_diag_stl, _ = cc_loss(z_ori_stl, z_stl_stl)\n",
    "        #on_diag_geo, _ = cc_loss(z_ori_geo, z_geo_geo)\n",
    "        #on_diag = on_diag_stl + on_diag_geo\n",
    "        #off_diag = cc_zero_loss(z_stl_geo, z_geo_stl)\n",
    "        \n",
    "        loss_barlow = config.w_on * /mnt/data/csprites/single_csprites_64x64_n7_c16_a16_p30_s1_bg_1_constant_color_70000on_diag + config.w_off * off_diag\n",
    "        \n",
    "        loss_zero = cc_zero_loss(z_stl_geo, z_geo_stl) + cc_zero_loss(z_stl_stl, z_geo_geo)\n",
    "        \n",
    "        ######################\n",
    "        # Total  LOSS\n",
    "        ######################\n",
    "        loss = config.w_barlow * loss_barlow + config.w_beta * loss_beta + loss_zero\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ######################\n",
    "        # Tack  Stats\n",
    "        ######################\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_step += 1 \n",
    "        epoch_loss_beta += loss_beta.item()\n",
    "        epoch_loss_barlow += loss_barlow.item()\n",
    "        epoch_loss_on += on_diag.item()\n",
    "        epoch_loss_off += off_diag.item()\n",
    "        epoch_a_min += a_z.min().item()\n",
    "        epoch_a_mean += a_z.mean().item()\n",
    "        epoch_a_max += a_z.max().item()\n",
    "        epoch_b_min += b_z.min().item()\n",
    "        epoch_b_mean += b_z.mean().item()\n",
    "        epoch_b_max += b_z.max().item()\n",
    "        #\n",
    "        global_step += 1\n",
    "        #\n",
    "        pbar.set_postfix(\n",
    "              {'L': loss.item(),\n",
    "               'L_cc': loss_barlow.item(),\n",
    "               'on': on_diag.item(),\n",
    "               'off': off_diag.item(),\n",
    "               'L_beta': loss_beta.item(),\n",
    "               'L_zero': loss_zero.item(),\n",
    "               'a_min': a_z.min().item(),\n",
    "               'a_max': a_z.max().item(),\n",
    "               'b_min': b_z.min().item(),\n",
    "               'b_max': b_z.max().item(),\n",
    "               'on_stl': on_diag_stl.item(),\n",
    "               'on_geo': on_diag_geo.item(),\n",
    "               }\n",
    "          )\n",
    "\n",
    "    stats.train.loss.append(epoch_loss / epoch_step)\n",
    "    stats.train.loss_beta.append(epoch_loss_beta / epoch_step)\n",
    "    stats.train.loss_barlow.append(epoch_loss_barlow / epoch_step)\n",
    "    stats.train.loss_on.append(epoch_loss_on / epoch_step)\n",
    "    stats.train.loss_off.append(epoch_loss_off / epoch_step)\n",
    "    stats.train.a_min.append(epoch_a_min / epoch_step)\n",
    "    stats.train.a_mean.append(epoch_a_mean / epoch_step)\n",
    "    stats.train.a_max.append(epoch_a_max / epoch_step)\n",
    "    stats.train.b_min.append(epoch_b_min / epoch_step)\n",
    "    stats.train.b_mean.append(epoch_b_mean / epoch_step)\n",
    "    stats.train.b_max.append(epoch_b_max / epoch_step)\n",
    "    stats.train.epoch.append(epoch_idx)\n",
    "\n",
    "    ################\n",
    "    # Linprob\n",
    "    ################\n",
    "    if epoch_idx % config.freqs.linprob == 0 or epoch_idx == config.num_epochs:\n",
    "        model.eval()\n",
    "        linacc, knnacc = utils.linprob_model(\n",
    "            model.beta_proj,\n",
    "            dl_linprob_valid,\n",
    "            device\n",
    "        )\n",
    "        print(\"    Linprob Beta @LR: {:.2f} @KNN: {:.2f}\".format(linacc, knnacc))\n",
    "        #\n",
    "        linacc, knnacc = utils.linprob_model(\n",
    "        model.backbone,\n",
    "        dl_linprob_valid,\n",
    "        device\n",
    "        )\n",
    "        print(\"    Linprob Back @LR: {:.2f} @KNN: {:.2f}\".format(linacc, knnacc))\n",
    "        stats.linprob.epoch.append(epoch_idx)\n",
    "        stats.linprob.knnacc.append(knnacc)\n",
    "        stats.linprob.linacc.append(linacc)\n",
    "        model.train()\n",
    "\n",
    "    ################\n",
    "    # PLOT FEATURES\n",
    "    ################\n",
    "    if epoch_idx % config.freqs.plot_features == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            R, Y = utils.get_representations(model.beta_proj, dl_eval_valid, device)\n",
    "        n_samples = 1000\n",
    "        idcs = np.random.choice(R.shape[0], size=n_samples, replace=False)\n",
    "        R = R[idcs]\n",
    "        Y = Y[idcs]\n",
    "        #\n",
    "        target_idx = 0\n",
    "        cmap = \"turbo\"\n",
    "        #\n",
    "        a_est, b_est = beta_params(R)\n",
    "        #\n",
    "        for idx in range(R.shape[1]):\n",
    "            title = \"a={:.3f} b={:.3f}\".format(a_est[idx], b_est[idx])\n",
    "            simplex_plot(R[:,idx], title=title, c=Y[:, target_idx], cmap=cmap)\n",
    "        \n",
    "    ################\n",
    "    # Checkpoint\n",
    "    ################\n",
    "    if epoch_idx % config.freqs.ckpt == 0 or epoch_idx == config.num_epochs:\n",
    "        print(\"save model!\")\n",
    "        if torch.cuda.device_count() > 1 and device != \"cpu\":\n",
    "            torch.save(model.module.state_dict(), p_ckpts / config.p_model.format(epoch_idx))\n",
    "        else:\n",
    "            torch.save(model.state_dict(), p_ckpts / config.p_model.format(epoch_idx))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1860ec9",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ea7038",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    R_train, Y_train = utils.get_representations(model.beta_proj, dl_eval_train, device)\n",
    "    R_valid, Y_valid = utils.get_representations(model.beta_proj, dl_eval_valid, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f10dd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "R = R_valid\n",
    "Y = Y_valid\n",
    "n_samples = 500\n",
    "idcs = np.random.choice(R.shape[0], size=n_samples, replace=False)\n",
    "R = R[idcs]\n",
    "Y = Y[idcs]\n",
    "#\n",
    "target_idx = 2\n",
    "\n",
    "cmap = \"turbo\"\n",
    "#\n",
    "a_est, b_est = beta_params(R)\n",
    "#\n",
    "for idx in range(R.shape[1]):\n",
    "    title = \"{:.3f} - {:.3f}\".format(a_est[idx], b_est[idx])\n",
    "    simplex_plot(R[:,idx], title=title, c=Y[:, target_idx], cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866f8ba",
   "metadata": {},
   "source": [
    "# ROW PLOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cab4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = []\n",
    "Y = []\n",
    "X = []\n",
    "with torch.no_grad():\n",
    "    for x, y in dl_linprob_valid:\n",
    "        x = x.to(device)\n",
    "        r = model.beta_proj(x)\n",
    "        X.append(inverse_norm_transform(x).detach().cpu().numpy())\n",
    "        R.append(r.detach().cpu().numpy())\n",
    "        Y.append(y.cpu().numpy())\n",
    "R = np.concatenate(R)\n",
    "Y = np.concatenate(Y)\n",
    "X = np.concatenate(X)\n",
    "X = np.transpose(X, axes=(0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0bdcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_imgs = 30\n",
    "topic_idcs = []\n",
    "for dim_idx in range(R.shape[1]):\n",
    "    r = R[:, dim_idx]\n",
    "    idcs = np.argsort(r)[-n_imgs:]\n",
    "    topic_idcs.append(idcs)\n",
    "topic_idcs = np.array(topic_idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2704d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = np.array(topic_idcs.shape) * 64\n",
    "img = np.zeros((h, w, 3))\n",
    "print(img.shape)\n",
    "n_rows, n_cols = topic_idcs.shape\n",
    "for row_idx in range(n_rows):\n",
    "    for col_idx in range(n_cols):\n",
    "        img_idx = topic_idcs[row_idx][col_idx]\n",
    "        img[row_idx * 64: row_idx * 64 + 64, col_idx * 64:col_idx * 64 + 64,:] = X[img_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01446d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=topic_idcs.shape)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a472d42",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- linprob backbone features + beta features\n",
    "- plot featuers\n",
    "- show crosscorrelation matrix\n",
    "- add all losses to pbar! what to do with weights?\n",
    "- show class distributions for all classes!\n",
    "- more workers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
