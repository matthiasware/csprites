{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f7af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c0113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "from pathlib import Path\n",
    "import os\n",
    "import warnings\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Extern\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.resnet import resnet18\n",
    "from dotted_dict import DottedDict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Local\n",
    "from BTwins.barlow import *\n",
    "from BTwins.transform_utils import *\n",
    "from csprites.datasets import ClassificationDataset\n",
    "import utils\n",
    "from backbone import get_backbone\n",
    "from optimizer import get_optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf57d64",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- Without geometric stuff transform!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50272c61",
   "metadata": {},
   "source": [
    "# Paper Stuff\n",
    "### Lrearning Rates\n",
    "Batch Size\tLearning Rate\n",
    "- 128  0.7\n",
    "- 256  0.4\n",
    "- 512  0.3\n",
    "- 1024 0.25\n",
    "- 2048 0.2\n",
    "- 4096 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a8065",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DualGeometricTransform(torch.nn.Module):\n",
    "    def __init__(self, img_size, scale, ratio, p_hflip, p_vflip):\n",
    "        super().__init__()\n",
    "        self.img_size = img_size\n",
    "        self.scale = scale\n",
    "        self.ratio = ratio\n",
    "        self.p_hflip = p_hflip\n",
    "        self.p_vflip = p_vflip\n",
    "    \n",
    "    def forward(self, img1, img2):\n",
    "        i, j, h, w = transforms.RandomResizedCrop.get_params(\n",
    "            img1,\n",
    "            scale=self.scale,\n",
    "            ratio=self.ratio)\n",
    "        img1 = transforms.functional.resized_crop(img1, i, j, h, w, self.img_size, Image.BICUBIC)\n",
    "        img2 = transforms.functional.resized_crop(img2, i, j, h, w, self.img_size, Image.BICUBIC)\n",
    "        \n",
    "        if torch.rand(1) < self.p_hflip:\n",
    "            img1 = transforms.functional.hflip(img1)\n",
    "            img2 = transforms.functional.hflip(img2)\n",
    "        if torch.rand(1) < self.p_vflip:\n",
    "            img1 = transforms.functional.vflip(img1)\n",
    "            img2 = transforms.functional.vflip(img2)\n",
    "        return img1, img2\n",
    "\n",
    "class CSpritesTransform(torch.nn.Module):\n",
    "    def __init__(self, img_size, scale, ratio, p_hflip, p_vflip, stl_transform, fin_transform):\n",
    "        super().__init__()\n",
    "        self.stl_transform = stl_transform\n",
    "        self.geo_transform = DualGeometricTransform(img_size, scale, ratio, p_hflip, p_vflip)\n",
    "        self.fin_transform = fin_transform\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.stl_transform(x)\n",
    "        x2 = self.stl_transform(x)\n",
    "        #\n",
    "        x11, x12 = self.geo_transform(x1, x2)\n",
    "        x21, x22 = self.geo_transform(x1, x2)\n",
    "        #\n",
    "        if self.fin_transform is not None:\n",
    "            x11 = self.fin_transform(x11)\n",
    "            x12 = self.fin_transform(x12)\n",
    "            x21 = self.fin_transform(x21)\n",
    "            x22 = self.fin_transform(x22)\n",
    "        return x11, x12, x21, x22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc87f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_lambda(d):\n",
    "    return 1/((d-1) * 0.0244)\n",
    "for d in [128, 256, 512, 1024, 2048, 4096, 8192]:\n",
    "    print(\"{:4}: {:.4f}\".format(d, calc_lambda(d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b78a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'device': 'cuda',\n",
    "    'cuda_visible_devices': '0',\n",
    "    'p_data': '/mnt/data/csprites/single_csprites_64x64_n7_c128_a32_p10_s3_bg_inf_random_function_100000',\n",
    "    'target_variable': 'shape',\n",
    "    'batch_size': 512,\n",
    "    'num_workers': 6,\n",
    "    'num_epochs': 100,\n",
    "    'freqs': {\n",
    "        'ckpt': 50,         # epochs\n",
    "        'linprob': 5,       # epochs\n",
    "    },\n",
    "    'num_vis': 64,\n",
    "    'backbone': \"ResNet-18\",\n",
    "    'optimizer': 'adam',\n",
    "    'optimizer_args': {\n",
    "        'lr': 0.001,\n",
    "        'weight_decay': 1e-6\n",
    "    },\n",
    "    'projector': [1024, 1024, 1024],\n",
    "    'scale_factor': 1,\n",
    "    'p_ckpts': \"ckpts\",\n",
    "    'p_model': \"model_{}.ckpt\",\n",
    "    'p_stats': \"stats.pkl\",\n",
    "    'p_config': 'config.pkl',\n",
    "    'p_R_train': 'R_train.npy',\n",
    "    'p_R_valid': 'R_valid.npy',\n",
    "    'p_Y_valid': 'Y_valid.npy',\n",
    "    'p_Y_train': 'Y_train.npy',\n",
    "    'linprob': {\n",
    "        'optimizer': 'adam',\n",
    "        'optimizer_args': {\n",
    "            'lr': 0.001,\n",
    "            'weight_decay': 1e-6\n",
    "        },\n",
    "        'n_hid': 0,\n",
    "        'd_hid': 1024,\n",
    "        'num_epochs': 1\n",
    "    }\n",
    "    \n",
    "}\n",
    "p_base = Path(\"/mnt/experiments/csprites\") / Path(config[\"p_data\"]).name / \"tmp\"\n",
    "#\n",
    "ts = time.time()\n",
    "st = datetime.datetime.fromtimestamp(ts).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "#\n",
    "config[\"p_experiment\"] = str(p_base / \"BTwins_bb_[{}]_target_[{}]_{}\".format(config[\"backbone\"],\n",
    "                                                           config[\"target_variable\"],\n",
    "                                                                            st))\n",
    "config['lambd'] = calc_lambda(config[\"projector\"][-1] // 2)\n",
    "config = DottedDict(config)\n",
    "pprint.pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH SETTINGS\n",
    "torch.backends.cudnn.benchmark = True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = config.cuda_visible_devices\n",
    "device = torch.device(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eff096",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f9494",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ds_config = Path(config.p_data) / \"config.pkl\"\n",
    "\n",
    "with open(p_ds_config, \"rb\") as file:\n",
    "    ds_config = pickle.load(file)\n",
    "\n",
    "target_variable = config.target_variable\n",
    "target_idx = [idx for idx, target in enumerate(ds_config[\"classes\"]) if target == target_variable][0]\n",
    "n_classes = ds_config[\"n_classes\"][target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441591bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_transform = utils.normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"])\n",
    "inverse_norm_transform = utils.inverse_normalize_transform(\n",
    "    ds_config[\"means\"],\n",
    "    ds_config[\"stds\"]\n",
    ")\n",
    "target_transform = lambda x: x[target_idx]\n",
    "#\n",
    "stl_transform = transforms.Compose([\n",
    "                transforms.RandomApply(\n",
    "                    [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                            saturation=0.2, hue=0.1)],\n",
    "                    p=0.8\n",
    "                ),\n",
    "                transforms.RandomGrayscale(p=0.2),\n",
    "                GaussianBlur(p=0.5),\n",
    "                Solarization(p=0.2)\n",
    "])\n",
    "fin_transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                norm_transform\n",
    "            ])\n",
    "\n",
    "train_transform = CSpritesTransform(\n",
    "    img_size=ds_config[\"img_size\"],\n",
    "    scale=(0.3, 1.0),\n",
    "    ratio=(1, 1),\n",
    "    p_hflip=(0.5),\n",
    "    p_vflip=(0.5),\n",
    "    stl_transform=stl_transform,\n",
    "    fin_transform=fin_transform)\n",
    "\n",
    "transform_linprob = transforms.Compose([\n",
    "                transforms.Resize(ds_config[\"img_size\"]),\n",
    "                transforms.ToTensor(),\n",
    "                norm_transform\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd96ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "ds_train = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=train_transform,\n",
    "    target_transform=target_transform,\n",
    "    split=\"train\"\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=False,\n",
    "    drop_last=True\n",
    ")\n",
    "# LINPROB\n",
    "ds_linprob = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=target_transform,\n",
    "    split=\"valid\"\n",
    ")\n",
    "dl_linprob = DataLoader(\n",
    "    ds_linprob,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers = config.num_workers,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdafdbd",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60176b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vis = 4 #config.num_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a319bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_train\n",
    "(x11, x12, x21, x22),_ = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e41a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x11 = inverse_norm_transform(x11[:n_vis])\n",
    "x12 = inverse_norm_transform(x12[:n_vis])\n",
    "x21 = inverse_norm_transform(x21[:n_vis])\n",
    "x22 = inverse_norm_transform(x22[:n_vis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137e38d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(x11, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a99e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(x12, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb832ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(x21, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6a1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_img = torchvision.utils.make_grid(x22, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ead3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dl_linprob_train\n",
    "x,y = next(iter(dl_linprob))\n",
    "x = x[:n_vis]\n",
    "y = y[:n_vis]\n",
    "#\n",
    "x = inverse_norm_transform(x)\n",
    "#\n",
    "grid_img = torchvision.utils.make_grid(x, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "#\n",
    "y = [ds_config[\"class_maps\"][\"shape\"][idx.item()] for idx in y]\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c96b87",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb975f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CspritesBarlowTwins(nn.Module):\n",
    "    '''\n",
    "    Adapted from https://github.com/facebookresearch/barlowtwins for arbitrary backbones, and arbitrary choice of which\n",
    "    latent representation to use. Designed for models which can fit on a single GPU (though training can be parallelized\n",
    "    across multiple as with any other model). Support for larger models can be done easily for individual use cases by\n",
    "    by following PyTorch's model parallelism best practices.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, backbone, projection_sizes, lambd, scale_factor=1):\n",
    "        '''\n",
    "\n",
    "        :param backbone: Model backbone\n",
    "        :param latent_id: name (or index) of the layer to be fed to the projection MLP\n",
    "        :param projection_sizes: size of the hidden layers in the projection MLP\n",
    "        :param lambd: tradeoff function\n",
    "        :param scale_factor: Factor to scale loss by, default is 1\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.lambd = lambd\n",
    "        self.scale_factor = scale_factor\n",
    "        # projector\n",
    "        sizes = [backbone.dim_out] + projection_sizes\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=False))\n",
    "            layers.append(nn.BatchNorm1d(sizes[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1], bias=False))\n",
    "        self.projector = nn.Sequential(*layers)\n",
    "\n",
    "        # normalization layer for the representations z1 and z2\n",
    "        assert projection_sizes[-1] % 2 == 0\n",
    "        \n",
    "        self.d_stl = projection_sizes[-1] // 2\n",
    "        self.d_geo = projection_sizes[-1] - self.d_stl\n",
    "        self.bn_stl = nn.BatchNorm1d(self.d_stl, affine=False)\n",
    "        self.bn_geo = nn.BatchNorm1d(self.d_geo, affine=False)\n",
    "\n",
    "    def get_representation(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def barlow_stl_loss(self, z1, z2):\n",
    "        # empirical cross-correlation matrix\n",
    "        c = self.bn_stl(z1).T @ self.bn_stl(z2)\n",
    "\n",
    "        # sum the cross-correlation matrix between all gpus\n",
    "        c.div_(z1.shape[0])\n",
    "\n",
    "        # use --scale-loss to multiply the loss by a constant factor\n",
    "        # see the Issues section of the readme\n",
    "        on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
    "        off_diag = off_diagonal(c).pow_(2).sum()\n",
    "        loss = self.scale_factor * (on_diag + self.lambd * off_diag)\n",
    "        return loss\n",
    "\n",
    "    def barlow_geo_loss(self, z1, z2):\n",
    "        # empirical cross-correlation matrix\n",
    "        c = self.bn_geo(z1).T @ self.bn_geo(z2)\n",
    "\n",
    "        # sum the cross-correlation matrix between all gpus\n",
    "        c.div_(z1.shape[0])\n",
    "\n",
    "        # use --scale-loss to multiply the loss by a constant factor\n",
    "        # see the Issues section of the readme\n",
    "        on_diag = torch.diagonal(c).add_(-1).pow_(2).sum()\n",
    "        off_diag = off_diagonal(c).pow_(2).sum()\n",
    "        loss = self.scale_factor * (on_diag + self.lambd * off_diag)\n",
    "        return loss\n",
    "        \n",
    "    def forward(self, y11, y12, y21, y22):\n",
    "        \"\"\"\n",
    "        same geo: (y11, y12),model = CspritesBarlowTwins(get_backbone(config.backbone, pretrained=False, zero_init_residual=True),\n",
    "                    config.projector,\n",
    "                    config.lambd,\n",
    "                    config.scale_factor) (y21, y22)\n",
    "        same stl: (y11, y21), (y12, y22)\n",
    "        \"\"\"\n",
    "        z11 = self.projector(self.backbone(y11))\n",
    "        z12 = self.projector(self.backbone(y12))\n",
    "        z21 = self.projector(self.backbone(y21))\n",
    "        z22 = self.projector(self.backbone(y22))\n",
    "        #\n",
    "        z11_stl = z11[:, :self.d_stl]\n",
    "        z11_geo = z11[:, self.d_stl:]\n",
    "        #\n",
    "        z12_stl = z12[:, :self.d_stl]\n",
    "        z12_geo = z12[:, self.d_stl:]\n",
    "        #\n",
    "        z21_stl = z21[:, :self.d_stl]\n",
    "        z21_geo = z21[:, self.d_stl:]\n",
    "        #\n",
    "        z22_stl = z22[:, :self.d_stl]\n",
    "        z22_geo = z22[:, self.d_stl:]\n",
    "        #\n",
    "        # GEO LOSS\n",
    "        geo_1112_loss = self.barlow_geo_loss(z11_geo, z12_geo)\n",
    "        geo_2122_loss = self.barlow_geo_loss(z21_geo, z22_geo)\n",
    "        \n",
    "        # STL LOSS\n",
    "        stl_1121_loss = self.barlow_stl_loss(z11_stl, z21_stl)\n",
    "        stl_1222_loss = self.barlow_stl_loss(z12_stl, z22_stl)\n",
    "        \n",
    "        loss = 0.25 * (geo_1112_loss + geo_2122_loss + stl_1121_loss + stl_1222_loss)\n",
    "        return loss, geo_1112_loss, geo_2122_loss, stl_1121_loss, stl_1222_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10130e4",
   "metadata": {},
   "source": [
    "# Test Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ca6b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CspritesBarlowTwins(get_backbone(config.backbone, pretrained=False, zero_init_residual=True),\n",
    "                    config.projector,\n",
    "                    config.lambd,\n",
    "                    config.scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f476d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x11, x12, x21, x22), y = next(iter(dl_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d71611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, geo_1112_loss, geo_2122_loss, stl_1121_loss, stl_1222_loss = model(x11, x12, x21, x22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3db08",
   "metadata": {},
   "source": [
    "# Prepare train run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5266be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CspritesBarlowTwins(get_backbone(config.backbone, pretrained=False, zero_init_residual=True),\n",
    "                    config.projector,\n",
    "                    config.lambd,\n",
    "                    config.scale_factor)\n",
    "#\n",
    "if torch.cuda.device_count() > 1 and device != \"cpu\":\n",
    "    print(\"Using {} gpus!\".format(torch.cuda.device_count()))\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.backbone = model.module.backbone\n",
    "elif device != \"cpu\":\n",
    "    print(\"Using 1 GPU!\")\n",
    "else:\n",
    "    print(\"Using CPU!\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337e69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eed836",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = get_optimizer(config.optimizer, model.parameters(), config.optimizer_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533b9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = {\n",
    "    'train': {\n",
    "        'loss': [],\n",
    "        'epoch': [],\n",
    "    },\n",
    "    'linprob': {\n",
    "        'linacc': [],\n",
    "        'knnacc': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "}\n",
    "stats = DottedDict(stats)\n",
    "#\n",
    "p_experiment = Path(config.p_experiment)\n",
    "p_experiment.mkdir(exist_ok=True, parents=True)\n",
    "p_ckpts = p_experiment / config.p_ckpts\n",
    "p_ckpts.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e245d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.p_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069d970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "for epoch_idx in range(1, config.num_epochs + 1, 1):\n",
    "    ################\n",
    "    # TRAIN\n",
    "    ################\n",
    "    model.train()\n",
    "    epoch_step = 0\n",
    "    epoch_loss = 0\n",
    "   \n",
    "    desc = \"Epoch [{:3}/{:3}] {}:\".format(epoch_idx, config.num_epochs, 'train')\n",
    "    pbar = tqdm(dl_train, bar_format= desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "    #\n",
    "    for (x11, x12, x21, x22), _ in pbar:\n",
    "        x11 = x11.to(device)\n",
    "        x12 = x12.to(device)\n",
    "        x21 = x21.to(device)\n",
    "        x22 = x22.to(device)\n",
    "        #\n",
    "        for param in model.parameters():\n",
    "            param.grad = None\n",
    "        loss, geo_1112_loss, geo_2122_loss, stl_1121_loss, stl_1222_loss = model(x11, x12, x21, x22)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_step += 1\n",
    "        global_step += 1\n",
    "        #\n",
    "        pbar.set_postfix({'loss': loss.item(),\n",
    "                          \"geo_1\": geo_1112_loss.item(),\n",
    "                          \"geo_2\": geo_2122_loss.item(),\n",
    "                          \"stl_1\": stl_1121_loss.item(),\n",
    "                          \"stl_2\": stl_1222_loss.item()\n",
    "                         })\n",
    "\n",
    "    stats.train.loss.append(epoch_loss / epoch_step)\n",
    "    stats.train.epoch.append(epoch_idx)\n",
    "\n",
    "    ################\n",
    "    # Linprob\n",
    "    ################\n",
    "    if epoch_idx % config.freqs.linprob == 0 or epoch_idx == config.num_epochs:\n",
    "        model.eval()\n",
    "        R = []\n",
    "        Y = []\n",
    "        with torch.no_grad():\n",
    "            for x, y in dl_linprob:\n",
    "                x = x.to(device)\n",
    "                r = model.backbone(x)\n",
    "                R.append(r.detach().cpu().numpy())\n",
    "                Y.append(y.cpu().numpy())\n",
    "        R = np.concatenate(R)\n",
    "        Y = np.concatenate(Y)\n",
    "        #\n",
    "        knn = KNeighborsClassifier(n_neighbors=5)\n",
    "        knn.fit(R, Y)\n",
    "        knnacc = knn.score(R, Y)\n",
    "        #\n",
    "        clf = LogisticRegression(random_state=0, tol=0.001, max_iter=200).fit(R, Y)\n",
    "        linacc = clf.score(R, Y)\n",
    "        print(\"    Linprob Eval @LR: {:.2f} @KNN: {:.2f}\".format(linacc, knnacc))\n",
    "        stats.linprob.epoch.append(epoch_idx)\n",
    "        stats.linprob.knnacc.append(knnacc)\n",
    "        stats.linprob.linacc.append(linacc)\n",
    "        model.train()\n",
    "    # Checkpoint\n",
    "    if epoch_idx % config.freqs.ckpt == 0 or epoch_idx == config.num_epochs:\n",
    "        print(\"save model!\")\n",
    "        if torch.cuda.device_count() > 1 and device != \"cpu\":\n",
    "            torch.save(model.module.state_dict(), p_ckpts / config.p_model.format(epoch_idx))\n",
    "        else:\n",
    "            torch.save(model.state_dict(), p_ckpts / config.p_model.format(epoch_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cad2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x1[:n_vis]\n",
    "x2 = x2[:n_vis]\n",
    "#\n",
    "x1 = x1.cpu()\n",
    "x2 = x2.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4420dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = inverse_norm_transform(x1)\n",
    "x2 = inverse_norm_transform(x2)\n",
    "#\n",
    "grid_img = torchvision.utils.make_grid(x1, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "grid_img = torchvision.utils.make_grid(x2, nrow=int(np.sqrt(n_vis)))\n",
    "plt.imshow(grid_img.permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "(x1 - x2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd23796",
   "metadata": {},
   "source": [
    "# Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03717e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "plt.plot(stats.train.epoch, stats.train.loss, label=\"train\")\n",
    "plt.legend()\n",
    "plt.savefig(p_experiment / \"barlow_loss.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot linprob loss\n",
    "#plt.plot(stats.linprob.epoch, stats.linprob.loss, label=\"train\")\n",
    "#plt.legend()\n",
    "#plt.savefig(p_experiment / \"linprob_loss.png\")\n",
    "#plt.show()\n",
    "\n",
    "# plot linprob acc\n",
    "plt.plot(stats.linprob.epoch, stats.linprob.knnacc, label=\"knn\")\n",
    "plt.plot(stats.linprob.epoch, stats.linprob.linacc, label=\"lin\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.savefig(p_experiment / \"linprob_acc.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a946ec7",
   "metadata": {},
   "source": [
    "# Save stats and config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb567d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_experiment / config.p_config, \"wb\") as file:\n",
    "    pickle.dump(config, file)\n",
    "with open(p_experiment / config.p_stats, \"wb\") as file:\n",
    "    pickle.dump(stats, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3549b78",
   "metadata": {},
   "source": [
    "# Get Representations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e41a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_R_train = p_experiment / config[\"p_R_train\"]\n",
    "p_Y_train = p_experiment / config[\"p_Y_train\"]\n",
    "p_R_valid = p_experiment / config[\"p_R_valid\"]\n",
    "p_Y_valid = p_experiment / config[\"p_Y_valid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "ds_train = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=None,\n",
    "    split=\"train\"\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=config.num_workers,\n",
    "    pin_memory=False,\n",
    "    drop_last=True\n",
    ")\n",
    "# LINPROB\n",
    "ds_valid = ClassificationDataset(\n",
    "    p_data = config.p_data,\n",
    "    transform=transform_linprob,\n",
    "    target_transform=None,\n",
    "    split=\"valid\"\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    ds_valid,\n",
    "    batch_size=config.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers = config.num_workers,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9676f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_train = []\n",
    "R_valid = []\n",
    "Y_train = []\n",
    "Y_valid = []\n",
    "#\n",
    "model.eval()\n",
    "for x, y in tqdm(dl_train):\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        r = model.backbone(x).detach().cpu().numpy()\n",
    "    R_train.append(r)\n",
    "    Y_train.append(y.numpy())\n",
    "#\n",
    "for x, y in tqdm(dl_valid):\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        r = model.backbone(x).detach().cpu().numpy()\n",
    "    R_valid.append(r)\n",
    "    Y_valid.append(y.numpy())\n",
    "\n",
    "R_train = np.concatenate(R_train)\n",
    "R_valid = np.concatenate(R_valid)\n",
    "Y_train = np.concatenate(Y_train)\n",
    "Y_valid = np.concatenate(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24f6b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(p_R_train, R_train)\n",
    "np.save(p_Y_train, Y_train)\n",
    "np.save(p_R_valid, R_valid)\n",
    "np.save(p_Y_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792c43b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_R_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d313d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65839516",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6e807",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
