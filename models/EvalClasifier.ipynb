{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843cebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e2769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80f575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import timeit\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from dotted_dict import DottedDict\n",
    "from tqdm import tqdm\n",
    "import pprint\n",
    "#\n",
    "from csprites.datasets import ClassificationDataset\n",
    "import utils\n",
    "from backbone import get_backbone\n",
    "from optimizer import get_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, n_classes, d_in, d_hid=1024, n_hid=0):\n",
    "        super(Net, self).__init__()\n",
    "        dims = [d_in]\n",
    "        for _ in range(n_hid):\n",
    "            dims.append(d_hid)\n",
    "        dims.append(n_classes)\n",
    "        #\n",
    "        layers = []\n",
    "        for idx in range(1, len(dims) - 1, 1):\n",
    "            layers.append(nn.Linear(dims[idx - 1], dims[idx]))\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(dims[-2], dims[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "def get_datasets(target_idx, p_R_train, p_R_valid, p_Y_train, p_Y_valid, batch_size):\n",
    "    #\n",
    "    R_train = torch.Tensor(np.load(p_R_train))\n",
    "    R_valid = torch.Tensor(np.load(p_R_valid))\n",
    "    #\n",
    "    Y_train = torch.LongTensor(np.load(p_Y_train))\n",
    "    Y_valid = torch.LongTensor(np.load(p_Y_valid))\n",
    "    #\n",
    "    d_r = R_train.shape[1]\n",
    "    #\n",
    "    Y_train = Y_train[:, target_idx]\n",
    "    Y_valid = Y_valid[:, target_idx]\n",
    "    #\n",
    "    ds_train = torch.utils.data.TensorDataset(R_train, Y_train)\n",
    "    ds_valid = torch.utils.data.TensorDataset(R_valid, Y_valid)\n",
    "\n",
    "    dl_train = DataLoader(\n",
    "        ds_train,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "    dl_valid = DataLoader(\n",
    "        ds_valid,\n",
    "        batch_size=batch_size,\n",
    "        pin_memory=True,\n",
    "        shuffle=True)\n",
    "    return dl_train, dl_valid, d_r\n",
    "\n",
    "def train_model(model, num_epochs, optimizer, criterion):\n",
    "    stats = {\n",
    "    'train': {\n",
    "        'loss': [],\n",
    "        'acc': [],\n",
    "        'epoch': [],\n",
    "    },\n",
    "    'valid': {\n",
    "        'loss': [],\n",
    "        'acc': [],\n",
    "        'epoch': [],\n",
    "    }\n",
    "    }\n",
    "    stats = DottedDict(stats)\n",
    "    desc_tmp = \"Epoch [{:3}/{:3}] {}:\"\n",
    "    #\n",
    "    for epoch_idx in range(1, num_epochs + 1, 1):\n",
    "        ################\n",
    "        # TRAIN\n",
    "        ################\n",
    "        model.train()\n",
    "        epoch_step = 0\n",
    "        epoch_loss = 0\n",
    "        epoch_total = 0\n",
    "        epoch_correct = 0\n",
    "        #\n",
    "        desc = desc_tmp.format(epoch_idx, num_epochs, 'train')\n",
    "        pbar = tqdm(dl_train, bar_format= desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "        #\n",
    "        for x, y in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #\n",
    "            _, y_pred = torch.max(out, 1)\n",
    "            total = y.size(0)\n",
    "            correct = (y_pred == y).sum().item()\n",
    "            #\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_total += total\n",
    "            epoch_correct += correct\n",
    "            epoch_step += 1\n",
    "            #\n",
    "            pbar.set_postfix({'loss': loss.item(), 'acc': correct / total})\n",
    "        stats.train.loss.append(epoch_loss / epoch_step)\n",
    "        stats.train.acc.append(epoch_correct / epoch_total)\n",
    "        stats.train.epoch.append(epoch_idx)\n",
    "\n",
    "        ################\n",
    "        # EVAL\n",
    "        ################\n",
    "        model.eval()\n",
    "        epoch_step = 0\n",
    "        epoch_loss = 0\n",
    "        epoch_total = 0\n",
    "        epoch_correct = 0\n",
    "        #\n",
    "        desc = desc_tmp.format(epoch_idx, num_epochs, 'valid')\n",
    "        pbar = tqdm(dl_valid, bar_format= desc + '{bar:10}{r_bar}{bar:-10b}')\n",
    "        #\n",
    "        for x, y in pbar:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(x)\n",
    "                loss = criterion(out, y)\n",
    "            #\n",
    "            _, y_pred = torch.max(out, 1)\n",
    "            total = y.size(0)\n",
    "            correct = (y_pred == y).sum().item()\n",
    "            #\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_total += total\n",
    "            epoch_correct += correct\n",
    "            epoch_step += 1\n",
    "            #\n",
    "            pbar.set_postfix({'loss': loss.item(), 'acc': correct / total})\n",
    "            #\n",
    "        stats.valid.loss.append(epoch_loss / epoch_step)\n",
    "        stats.valid.acc.append(epoch_correct / epoch_total)\n",
    "        stats.valid.epoch.append(epoch_idx)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad211d7",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d644275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linprob config\n",
    "linprob_config = {\n",
    "    'p_eval': 'eval',\n",
    "    'p_eval_results': 'results.pkl',\n",
    "    'p_config': \"linprob_config.pkl\",\n",
    "    'p_results': 'results.pkl',\n",
    "    'device': \"cuda\",\n",
    "    'cuda_visible_devices': '0',\n",
    "    'n_hid': 0,\n",
    "    'd_hid': 1024,\n",
    "    'batch_size': 1024,\n",
    "    'optimizer': 'adam',\n",
    "    'optimizer_args': {'lr': 0.001, 'weight_decay': 1e-6},\n",
    "    'num_epochs': 40,\n",
    "}\n",
    "linprob_config = DottedDict(linprob_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH SETTINGS\n",
    "torch.backends.cudnn.benchmark = True\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = linprob_config.cuda_visible_devices\n",
    "device = torch.device(linprob_config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_experiments_base = Path(\"/mnt/experiments/csprites/single_csprites_64x64_n7_c128_a32_p10_s3_bg_inf_random_function_100000\")\n",
    "p_experiments = [\n",
    "#    p_experiments_base / \"SUP_[ResNet-18]_target_[shape]\",\n",
    "#    p_experiments_base / \"SUP_[ResNet-18]_target_[scale]\",\n",
    "#    p_experiments_base / \"SUP_[ResNet-18]_target_[color]\",\n",
    "#    p_experiments_base / \"SUP_[ResNet-18]_target_[angle]\",\n",
    "#    p_experiments_base / \"SUP_[ResNet-18]_target_[py]\",\n",
    "#    p_experiments_base / \"SUP_[ResNet-18]_target_[px]\",\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_LARS',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_Adam',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_aug_GEO_only',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_aug_STYLE_only',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_4L_dp_2048',\n",
    "    #p_experiments_base / 'BTwins_[ResNet-18]_4L_geo_style_02_08',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_4L_geo_style_05_05',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_4L_geo_style_08_02',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_geo_style_50_50_100'\n",
    "]\n",
    "for p in p_experiments:\n",
    "    assert p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2a7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = {}\n",
    "for p_experiment in p_experiments:\n",
    "    experiment_name = p_experiment.name\n",
    "    print(experiment_name)\n",
    "    #\n",
    "    # experiment config\n",
    "    p_experiment_config = p_experiment / \"config.pkl\"\n",
    "    with open(p_experiment_config, \"rb\") as file:\n",
    "        experiment_config = pickle.load(file)\n",
    "    #\n",
    "    # dataset config\n",
    "    p_ds_config = Path(experiment_config.p_data) / \"config.pkl\"\n",
    "    with open(p_ds_config, \"rb\") as file:\n",
    "        ds_config = pickle.load(file)\n",
    "    \n",
    "    results = {}\n",
    "    for target_variable in ds_config[\"classes\"]:\n",
    "        print(target_variable)\n",
    "        #\n",
    "        target_idx = [idx for idx, target in enumerate(ds_config[\"classes\"]) if target == target_variable][0]\n",
    "        n_classes = ds_config[\"n_classes\"][target_variable]\n",
    "        #\n",
    "        dl_train, dl_valid, d_r = get_datasets(target_idx,\n",
    "                                               p_experiment / experiment_config[\"p_R_train\"],\n",
    "                                               p_experiment / experiment_config[\"p_R_valid\"],\n",
    "                                               p_experiment / experiment_config[\"p_Y_train\"],\n",
    "                                               p_experiment / experiment_config[\"p_Y_valid\"],\n",
    "                                               linprob_config.batch_size\n",
    "                                              )\n",
    "        #\n",
    "        model = Net(n_classes, d_r, linprob_config.d_hid, linprob_config.n_hid)\n",
    "        model = model.to(device)\n",
    "        #\n",
    "        optimizer = get_optimizer(linprob_config.optimizer, model.parameters(), linprob_config.optimizer_args)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        #\n",
    "        stats = train_model(model, linprob_config.num_epochs, optimizer, criterion)\n",
    "        results[target_variable] = stats\n",
    "\n",
    "        # plot losses\n",
    "        fig, axes = plt.subplots(1, 2)\n",
    "        axes[0].plot(stats.train.epoch, stats.train.loss, label=\"train\")\n",
    "        axes[0].plot(stats.valid.epoch, stats.valid.loss, label=\"valid\")\n",
    "        #axes[0].set_yscale('log')\n",
    "        axes[0].set_title(\"Loss\")\n",
    "        axes[0].legend()\n",
    "\n",
    "\n",
    "        # plot accs\n",
    "        axes[1].plot(stats.train.epoch, stats.train.acc, label=\"train\")\n",
    "        axes[1].plot(stats.valid.epoch, stats.valid.acc, label=\"valid\")\n",
    "        #axes[1].set_yscale('log')\n",
    "        axes[1].set_title(\"Acc\")\n",
    "        axes[1].legend()\n",
    "        #\n",
    "        fig.suptitle(target_variable)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    p_results = p_experiment / linprob_config[\"p_results\"]\n",
    "    p_linprob_config = p_experiment / linprob_config[\"p_config\"]\n",
    "    #\n",
    "    with open(p_results, \"wb\") as file:\n",
    "        pickle.dump(results, file)\n",
    "    with open(p_linprob_config, \"wb\") as file:\n",
    "        pickle.dump(linprob_config, file)\n",
    "    experiment_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3833587",
   "metadata": {},
   "source": [
    "# Load all results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc774394",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_experiments = [\n",
    "    p_experiments_base / \"SUP_[ResNet-18]_target_[shape]\",\n",
    "    p_experiments_base / \"SUP_[ResNet-18]_target_[scale]\",\n",
    "    p_experiments_base / \"SUP_[ResNet-18]_target_[color]\",\n",
    "    p_experiments_base / \"SUP_[ResNet-18]_target_[angle]\",\n",
    "    p_experiments_base / \"SUP_[ResNet-18]_target_[py]\",\n",
    "    p_experiments_base / \"SUP_[ResNet-18]_target_[px]\",\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_LARS',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_Adam',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_aug_STYLE_only',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_aug_GEO_only',\n",
    "    #p_experiments_base / 'BTwins_[ResNet-18]_4L_dp_2048',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_4L_geo_style_02_08',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_4L_geo_style_05_05',\n",
    "    p_experiments_base / 'BTwins_[ResNet-18]_4L_geo_style_08_02',\n",
    "#    p_experiments_base / 'BTwins_[ResNet-18]_geo_style_50_50_100'\n",
    "]\n",
    "for p in p_experiments:\n",
    "    if not p.exists():\n",
    "        print(p)\n",
    "    assert p.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdaa292",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_results = {}\n",
    "for p_experiment in p_experiments:\n",
    "    experiment_name = p_experiment.name\n",
    "    print(experiment_name)\n",
    "    #\n",
    "    p_results = p_experiment / linprob_config[\"p_results\"]\n",
    "    #\n",
    "    with open(p_results, \"rb\") as file:\n",
    "        results = pickle.load(file)\n",
    "    experiment_results[experiment_name] = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_eval =  p_experiments_base / linprob_config[\"p_eval\"]\n",
    "p_eval.mkdir(exist_ok=True)\n",
    "p_results = p_eval / linprob_config[\"p_results\"]\n",
    "p_config = p_eval / linprob_config[\"p_config\"]\n",
    "p_plot = p_eval / \"results.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a11983",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(p_results, \"wb\") as file:\n",
    "    pickle.dump(experiment_results, file)\n",
    "with open(p_config, \"wb\") as file:\n",
    "    pickle.dump(linprob_config, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a913557",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_avrg = 5\n",
    "results = {}\n",
    "model_names = list(experiment_results.keys())\n",
    "target_variables = list(experiment_results[model_names[0]].keys())\n",
    "all_accs = []\n",
    "for model_name in model_names:\n",
    "    model_accs = []\n",
    "    for target_variable in target_variables:\n",
    "        accs = experiment_results[model_name][target_variable][\"valid\"]['acc'][-n_avrg:]\n",
    "        acc = sum(accs) / len(accs)\n",
    "        model_accs.append(acc)\n",
    "    all_accs.append(model_accs)\n",
    "accs = np.array(all_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95015e3a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scale_factor = 2\n",
    "n_rows = len(model_names)\n",
    "n_cols = len(target_variables)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(n_cols * scale_factor,\n",
    "                                n_rows * scale_factor))\n",
    "im = ax.imshow(accs, cmap=\"copper\")\n",
    "#\n",
    "ax.set_xticks(np.arange(len(target_variables)))\n",
    "ax.set_yticks(np.arange(len(model_names)))\n",
    "#\n",
    "ax.set_xticklabels(target_variables)\n",
    "ax.set_yticklabels(model_names)\n",
    "#\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# Loop over data dimensions and create text annotations.\n",
    "for col_idx in range(len(target_variables)):\n",
    "    for row_idx in range(len(model_names)):\n",
    "        text = ax.text(col_idx, row_idx, \"{:.2f}\".format(accs[row_idx, col_idx]),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "        #text = ax.text(col_idx, row_idx, \"r{},c{}\".format(row_idx, col_idx))\n",
    "\n",
    "ax.set_title(\"Accs\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(p_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573a451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row means\n",
    "means = accs.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, mean in zip(model_names, means):\n",
    "    print(\"{:<40}: {:.2f}\".format(model_name, mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a9b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabdd612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
